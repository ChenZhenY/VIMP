\hypertarget{OptimizerPriorCollisionGH_8h_source}{}\doxysection{Optimizer\+Prior\+Collision\+GH.\+h}
\label{OptimizerPriorCollisionGH_8h_source}\index{include/OptimizerPriorCollisionGH.h@{include/OptimizerPriorCollisionGH.h}}
\mbox{\hyperlink{OptimizerPriorCollisionGH_8h}{Go to the documentation of this file.}}
\begin{DoxyCode}{0}
\DoxyCodeLine{1 }
\DoxyCodeLine{13 }
\DoxyCodeLine{14 \textcolor{preprocessor}{\#include <gtsam/base/Matrix.h>}}
\DoxyCodeLine{15 \textcolor{preprocessor}{\#include <iostream>}}
\DoxyCodeLine{16 \textcolor{preprocessor}{\#include <random>}}
\DoxyCodeLine{17 \textcolor{preprocessor}{\#include <utility>}}
\DoxyCodeLine{18 \textcolor{preprocessor}{\#include "{}\mbox{\hyperlink{SparseInverseMatrix_8h}{SparseInverseMatrix.h}}"{}}}
\DoxyCodeLine{19 \textcolor{preprocessor}{\#include "{}\mbox{\hyperlink{OptimizerFactorizedPriorCollisionGH_8h}{OptimizerFactorizedPriorCollisionGH.h}}"{}}}
\DoxyCodeLine{20 \textcolor{preprocessor}{\#include <boost/scoped\_ptr.hpp>}}
\DoxyCodeLine{21 }
\DoxyCodeLine{22 \textcolor{comment}{//using namespace GaussianSampler;}}
\DoxyCodeLine{23 \textcolor{keyword}{using namespace }std;}
\DoxyCodeLine{24 \textcolor{keyword}{using namespace }SparseInverse;}
\DoxyCodeLine{25 \textcolor{keyword}{typedef} Triplet<double> T;}
\DoxyCodeLine{26 }
\DoxyCodeLine{27 \textcolor{keyword}{namespace }MPVI\{}
\DoxyCodeLine{28     \textcolor{keyword}{template} <\textcolor{keyword}{typename} Function, \textcolor{keyword}{typename} PriorClass, \textcolor{keyword}{typename} CollisionClass, \textcolor{keyword}{typename}... Args>}
\DoxyCodeLine{29 }
\DoxyCodeLine{30 \textcolor{comment}{// template function and classes to calculate the costs}}
\DoxyCodeLine{31 \textcolor{keyword}{class }\mbox{\hyperlink{classMPVI_1_1VIMPOptimizerPriorColGH}{VIMPOptimizerPriorColGH}}\{}
\DoxyCodeLine{32     \textcolor{keyword}{using }\mbox{\hyperlink{classMPVI_1_1OptimizerFactorizedPriorColGH}{FactorizedOptimizer}} = \mbox{\hyperlink{classMPVI_1_1OptimizerFactorizedPriorColGH}{OptimizerFactorizedPriorColGH}}<Function, PriorClass, CollisionClass, Args ...>;}
\DoxyCodeLine{33 }
\DoxyCodeLine{34 \textcolor{keyword}{public}:}
\DoxyCodeLine{35     \mbox{\hyperlink{classMPVI_1_1VIMPOptimizerPriorColGH_a48f8c9d8fd61f4a716cea34ba0185ab0}{VIMPOptimizerGH}}(\textcolor{keyword}{const} \textcolor{keywordtype}{int}\& dimension, \textcolor{keyword}{const} \textcolor{keywordtype}{int}\& sub\_dim, \textcolor{keyword}{const} vector<Function>\& \_vec\_function,}
\DoxyCodeLine{36                                    \textcolor{keyword}{const} vector<Function>\& \_vec\_function,}
\DoxyCodeLine{37                                    \textcolor{keyword}{const} vector<PriorClass>\& \_vec\_prior,}
\DoxyCodeLine{38                                    \textcolor{keyword}{const} vector<CollisionClass>\& \_vec\_collision,}
\DoxyCodeLine{39                                    \textcolor{keyword}{const} vector<MatrixXd>\& \_vec\_Pks):}
\DoxyCodeLine{40                                    dim\{dimension\},}
\DoxyCodeLine{41                                    sub\_dim\{sub\_dim\},}
\DoxyCodeLine{42                                    num\_sub\_vars\{static\_cast<int>(\_vec\_Pks.size())\},}
\DoxyCodeLine{43                                    vec\_cost\_function\_\{\_vec\_function\},}
\DoxyCodeLine{44                                    vec\_prior\_\{\_vec\_prior\},}
\DoxyCodeLine{45                                    vec\_collision\_\{\_vec\_collision\},}
\DoxyCodeLine{46                                    vec\_Pks\_\{\_vec\_Pks\},}
\DoxyCodeLine{47                                    mu\_\{VectorXd::Zero(dimension)\},}
\DoxyCodeLine{48                                    d\_mu\_\{VectorXd::Zero(dimension)\},}
\DoxyCodeLine{49                                    precision\_\{MatrixXd::Identity(dim, dim) * 5.0\},}
\DoxyCodeLine{50                                    d\_precision\_(MatrixXd::Identity(dim, dim)),}
\DoxyCodeLine{51                                    Vdmu\_\{VectorXd::Zero(dimension)\},}
\DoxyCodeLine{52                                    Vddmu\_(MatrixXd::Identity(dim, dim)),}
\DoxyCodeLine{53                                    inverser\_\{MatrixXd::Identity(dim, dim)\}\{}
\DoxyCodeLine{54 }
\DoxyCodeLine{56         \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i=0; i<num\_sub\_vars; i++)\{}
\DoxyCodeLine{57 }
\DoxyCodeLine{58             \mbox{\hyperlink{classMPVI_1_1OptimizerFactorizedPriorColGH}{FactorizedOptimizer}} optimizer\_k\{sub\_dim, vec\_cost\_function\_[i]\};}
\DoxyCodeLine{59             vec\_factor\_optimizers\_.emplace\_back(optimizer\_k);}
\DoxyCodeLine{60         \}}
\DoxyCodeLine{61     \}}
\DoxyCodeLine{62 \textcolor{keyword}{protected}:}
\DoxyCodeLine{63     \textcolor{comment}{// optimization variables}}
\DoxyCodeLine{64     \textcolor{keywordtype}{int} dim, sub\_dim, num\_sub\_vars;}
\DoxyCodeLine{65 }
\DoxyCodeLine{66     VectorXd mu\_, Vdmu\_, d\_mu\_;}
\DoxyCodeLine{67     MatrixXd precision\_, Vddmu\_, d\_precision\_;}
\DoxyCodeLine{68 }
\DoxyCodeLine{69     \textcolor{comment}{// sampler}}
\DoxyCodeLine{70     vector<FactorizedOptimizer> vec\_factor\_optimizers\_;}
\DoxyCodeLine{71 }
\DoxyCodeLine{72     \textcolor{comment}{// cost functional. Input: samples vector; Output: cost}}
\DoxyCodeLine{73     \textcolor{keyword}{const} vector<Function> vec\_cost\_function\_;}
\DoxyCodeLine{74     \textcolor{keyword}{const} vector<PriorClass> vec\_prior\_,}
\DoxyCodeLine{75     \textcolor{keyword}{const} vector<CollisionClass> vec\_collision\_,}
\DoxyCodeLine{76     \textcolor{keyword}{const} vector<MatrixXd> vec\_Pks\_;}
\DoxyCodeLine{77 }
\DoxyCodeLine{78     \textcolor{comment}{// Sparse matrix inverse helper}}
\DoxyCodeLine{79     \mbox{\hyperlink{structSparseInverse_1_1dense__inverser}{dense\_inverser}} inverser\_;}
\DoxyCodeLine{80     \textcolor{keywordtype}{double} step\_size\_precision = 0.9;}
\DoxyCodeLine{81     \textcolor{keywordtype}{double} step\_size\_mu = 0.9;}
\DoxyCodeLine{82 }
\DoxyCodeLine{83 \textcolor{keyword}{public}:}
\DoxyCodeLine{84 }
\DoxyCodeLine{85     \textcolor{keywordtype}{void} step()\{}
\DoxyCodeLine{86         cout << \textcolor{stringliteral}{"{}mu\_ "{}} << endl << mu\_ << endl;}
\DoxyCodeLine{87 }
\DoxyCodeLine{88         Vdmu\_.setZero();}
\DoxyCodeLine{89         Vddmu\_.setZero();}
\DoxyCodeLine{90         d\_mu\_.setZero();}
\DoxyCodeLine{91         d\_precision\_.setZero();}
\DoxyCodeLine{92 }
\DoxyCodeLine{93         MatrixXd Sigma\{inverser\_.\mbox{\hyperlink{structSparseInverse_1_1dense__inverser_a58b2afee2028386c8410837a0c11db85}{inverse}}(precision\_)\};}
\DoxyCodeLine{94 }
\DoxyCodeLine{95         \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} k=0; k<num\_sub\_vars; k++)\{}
\DoxyCodeLine{96 }
\DoxyCodeLine{97             \textcolor{keyword}{const} MatrixXd\& Pk = vec\_Pks\_[k];}
\DoxyCodeLine{98 }
\DoxyCodeLine{99             \textcolor{keyword}{auto} \&optimizer\_k = vec\_factor\_optimizers\_[k];}
\DoxyCodeLine{100 }
\DoxyCodeLine{101             optimizer\_k.update\_mu(VectorXd\{Pk*mu\_\});}
\DoxyCodeLine{102             optimizer\_k.update\_precision(MatrixXd\{(Pk * Sigma * Pk.transpose()).inverse()\});}
\DoxyCodeLine{103 }
\DoxyCodeLine{104             optimizer\_k.calculate\_partial\_V();}
\DoxyCodeLine{105 }
\DoxyCodeLine{106             Vdmu\_ = Vdmu\_ + Pk.transpose() * optimizer\_k.get\_Vdmu();}
\DoxyCodeLine{107             Vddmu\_ = Vddmu\_ + Pk.transpose().eval() * optimizer\_k.get\_Vddmu() * Pk;}
\DoxyCodeLine{108 }
\DoxyCodeLine{109         \}}
\DoxyCodeLine{110 }
\DoxyCodeLine{111         d\_precision\_ = -\/precision\_ + Vddmu\_;}
\DoxyCodeLine{112 }
\DoxyCodeLine{113         precision\_ = precision\_ + step\_size\_precision*d\_precision\_;}
\DoxyCodeLine{114 }
\DoxyCodeLine{115         d\_mu\_ = precision\_.colPivHouseholderQr().solve(-\/Vdmu\_);}
\DoxyCodeLine{116 }
\DoxyCodeLine{117         mu\_ = mu\_ + step\_size\_mu * d\_mu\_;}
\DoxyCodeLine{118 }
\DoxyCodeLine{119         cout << \textcolor{stringliteral}{"{}mu\_ "{}} << endl << mu\_ << endl;}
\DoxyCodeLine{120         cout << \textcolor{stringliteral}{"{}new precision "{}} << endl << precision\_ << endl;}
\DoxyCodeLine{121 }
\DoxyCodeLine{122     \}}
\DoxyCodeLine{123 }
\DoxyCodeLine{124     \textcolor{keywordtype}{void} step\_closed\_form()\{}
\DoxyCodeLine{125 }
\DoxyCodeLine{126         Vdmu\_.setZero();}
\DoxyCodeLine{127         Vddmu\_.setZero();}
\DoxyCodeLine{128         d\_mu\_.setZero();}
\DoxyCodeLine{129         d\_precision\_.setZero();}
\DoxyCodeLine{130 }
\DoxyCodeLine{131         MatrixXd Sigma\{inverser\_.\mbox{\hyperlink{structSparseInverse_1_1dense__inverser_a58b2afee2028386c8410837a0c11db85}{inverse}}(precision\_)\};}
\DoxyCodeLine{132 }
\DoxyCodeLine{133         \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} k=0; k<num\_sub\_vars; k++)\{}
\DoxyCodeLine{134 }
\DoxyCodeLine{135             \textcolor{keyword}{const} MatrixXd\& Pk = vec\_Pks\_[k];}
\DoxyCodeLine{136 }
\DoxyCodeLine{137             \textcolor{keyword}{auto} \&optimizer\_k = vec\_factor\_optimizers\_[k];}
\DoxyCodeLine{138             optimizer\_k.updateSamplerMean(VectorXd\{Pk * mu\_\});}
\DoxyCodeLine{139             optimizer\_k.updateSamplerCovarianceMatrix(MatrixXd\{Pk * Sigma * Pk.transpose()\});}
\DoxyCodeLine{140 }
\DoxyCodeLine{141             optimizer\_k.update\_mu(VectorXd\{Pk*mu\_\});}
\DoxyCodeLine{142             optimizer\_k.update\_precision(MatrixXd\{(Pk * Sigma * Pk.transpose()).inverse()\});}
\DoxyCodeLine{143 }
\DoxyCodeLine{144             \textcolor{comment}{// closed form verification for a Gaussian posterior}}
\DoxyCodeLine{145 \textcolor{comment}{//            auto \&cost\_class\_k = vec\_cost\_class\_[k];}}
\DoxyCodeLine{146 \textcolor{comment}{//            optimizer\_k.calculate\_exact\_partial\_V(cost\_class\_k.get\_mean(), cost\_class\_k.get\_covariance());}}
\DoxyCodeLine{147 }
\DoxyCodeLine{148             optimizer\_k.calculate\_partial\_V();}
\DoxyCodeLine{149 }
\DoxyCodeLine{150             Vdmu\_ = Vdmu\_ + Pk.transpose() * optimizer\_k.get\_Vdmu();}
\DoxyCodeLine{151             Vddmu\_ = Vddmu\_ + Pk.transpose().eval() * optimizer\_k.get\_Vddmu() * Pk;}
\DoxyCodeLine{152         \}}
\DoxyCodeLine{153 }
\DoxyCodeLine{154         d\_precision\_ = -\/precision\_ + Vddmu\_;}
\DoxyCodeLine{155 }
\DoxyCodeLine{156         precision\_ = precision\_ + step\_size\_precision*d\_precision\_;}
\DoxyCodeLine{157 }
\DoxyCodeLine{158         d\_mu\_ = precision\_.colPivHouseholderQr().solve(-\/Vdmu\_);}
\DoxyCodeLine{159         mu\_ = mu\_ + step\_size\_mu * d\_mu\_;}
\DoxyCodeLine{160 }
\DoxyCodeLine{161         cout << \textcolor{stringliteral}{"{}mu\_ "{}} << endl << mu\_ << endl;}
\DoxyCodeLine{162         cout << \textcolor{stringliteral}{"{}new precision "{}} << endl << precision\_ << endl;}
\DoxyCodeLine{163 }
\DoxyCodeLine{164     \}}
\DoxyCodeLine{165 }
\DoxyCodeLine{166     gtsam::Vector get\_mean()\{}
\DoxyCodeLine{167         \textcolor{keywordflow}{return} mu\_;}
\DoxyCodeLine{168     \}}
\DoxyCodeLine{169 }
\DoxyCodeLine{170     gtsam::Matrix get\_precision()\{}
\DoxyCodeLine{171         \textcolor{keywordflow}{return} precision\_;}
\DoxyCodeLine{172     \}}
\DoxyCodeLine{173 }
\DoxyCodeLine{174     gtsam::Matrix get\_covariance()\{}
\DoxyCodeLine{175         \textcolor{keywordflow}{return} inverser\_.\mbox{\hyperlink{structSparseInverse_1_1dense__inverser_a58b2afee2028386c8410837a0c11db85}{inverse}}();}
\DoxyCodeLine{176     \}}
\DoxyCodeLine{177 }
\DoxyCodeLine{178     \textcolor{keywordtype}{void} set\_step\_size(\textcolor{keywordtype}{double} ss\_mean, \textcolor{keywordtype}{double} ss\_precision)\{}
\DoxyCodeLine{179         step\_size\_mu = ss\_mean;}
\DoxyCodeLine{180         step\_size\_precision = ss\_precision;}
\DoxyCodeLine{181     \}}
\DoxyCodeLine{182 }
\DoxyCodeLine{183     \textcolor{keywordtype}{void} set\_mu(\textcolor{keyword}{const} VectorXd\& mean)\{}
\DoxyCodeLine{184         mu\_ = mean;}
\DoxyCodeLine{185     \}}
\DoxyCodeLine{186  }
\DoxyCodeLine{187 \};}
\DoxyCodeLine{188 }
\DoxyCodeLine{189 \}}

\end{DoxyCode}
